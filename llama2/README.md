# LLaMA2

My attempt at implementing LLaMA2.

## References

### Blogs

- [LLaMA-2 from the Ground Up by Cameron R. Wolfe](https://substack.com/home/post/p-135824233)
- [Rotary Position Embeddings by EleutherAI](https://blog.eleuther.ai/rotary-embeddings/)
- [The Practical Guide to LLMs - LLaMA-2 by Georgian Impact Blog](https://medium.com/georgian-impact-blog/the-practical-guide-to-llms-llama-2-cdf21d540ce3)


### Papers

- [LLaMA2 Paper](https://arxiv.org/abs/2402.12578)
- [Group Query Attention Paper](https://arxiv.org/abs/2305.13245)
- [RMSNorm Paper](https://arxiv.org/abs/1910.07467)
- [SwiGLU Paper](https://arxiv.org/abs/2002.05202)
- [RoPE Paper](https://arxiv.org/abs/2104.09864)

### Repos

- [LLaMA Cookbook](https://github.com/meta-llama/llama-cookbook)
- [Official LLaMA2 Implementation](https://github.com/facebookresearch/llama/blob/main/llama/model.py)
- [Georgian Impact Blog's LLaMA2 Implementation](https://github.com/georgian-io/LLM-Finetuning-Toolkit/tree/main/llama2)
